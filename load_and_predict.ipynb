{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25dff934-04b8-4de9-9494-fa70c2daf74a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3770/501805711.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2025-07-28 08:24:10.625577: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-28 08:24:10.698972: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from tqdm.autonotebook import tqdm\n",
    "import keras\n",
    "from surgeNN import io,preprocessing\n",
    "import datetime\n",
    "import fnmatch\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "#NOTE: keras & tensorflow versions must align with the versions used to train the models (see req.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a3cda5-b4c7-49bd-a22a-1a6888378c85",
   "metadata": {},
   "source": [
    "Notebook to load trained model and apply to forcing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5eec073-bbab-4c4a-b81a-c66bcea5b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the script\n",
    "performance_path = '/home/jovyan/surgeNN/results/nns_codec/performance/lstm/lstm_3h_den_helder-denhdr-nld-rws_mse_hp1_ndeg3_it0.nc'\n",
    "model_fns = [os.path.join('/home/jovyan/surgeNN/results/nns_codec/keras_models/lstm',k) for k in os.listdir('/home/jovyan/test_surge_models/results/nns_codec/keras_models/lstm') if k.endswith('keras')]\n",
    "\n",
    "predictor_path = 'gs://leap-persistent/timh37/HighResMIP/surgeNN_predictors/' #path to predictor data derived from highresmip model\n",
    "\n",
    "#adapt script so that it can loop over multiple models: have base script work on single model, script around it to loop over performances?\n",
    "out_path = '/home/jovyan/surgeNN/results/nns_hadgem3/codec_trained_predictions'\n",
    "out_fn = 'predictions_hadgem3_forced_codec_trained_lstm'\n",
    "predictor_vars = ['msl','u10','v10'] #must align with what was used training (to-do: store this in performance output atrributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb747fde-d8a3-4f6a-b33b-b27044465ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance = xr.open_dataset(performance_path)\n",
    "hyperparams = performance.hyperparameters.copy(deep=True)\n",
    "performance = performance.isel(i=0,drop=True) #model_i or model_it doesn't matter here, as o & n_steps is the same for all models\n",
    "tg = performance.tg.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31b2746-52df-4073-8265-57396adb5ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_predict(performance,tg,model_fns,predictor_path,predictor_vars,out_path,out_fn):\n",
    "    performance = performance.sel(tg=tg)\n",
    "    n_steps = int(performance.hyperparameters.sel(p='n_steps').isel(split=0).values)\n",
    "\n",
    "    #load predictors\n",
    "    predictors = io.Predictor(predictor_path)\n",
    "    predictors.open_dataset(tg,predictor_vars,performance.n_cells)\n",
    "\n",
    "    if 'intake_esm_attrs:source_id' in predictors.data.attrs and predictors.data.attrs['intake_esm_attrs:source_id'] == 'HadGEM3-GC31-HM':\n",
    "        time = predictors.data.time\n",
    "        where_diff_not_3h = np.where(np.diff(predictors.data.time) !=  datetime.timedelta(seconds=10800))[0][0] #01-01-2015 00:00:00 is missing, but also in predictand data -> not an issue?\n",
    "\n",
    "        newtime = np.hstack([time.values,time.values[-1]])\n",
    "        newtime[0:where_diff_not_3h+1] = time.values[0:where_diff_not_3h+1]\n",
    "        newtime[where_diff_not_3h+2::] = time.values[where_diff_not_3h+1::]\n",
    "        newtime[where_diff_not_3h+1] = newtime[where_diff_not_3h+1] - datetime.timedelta(seconds=10800)\n",
    "\n",
    "        predictors.data = predictors.data.reindex(time=newtime,method='ffill') #repeat previous datapoint\n",
    "\n",
    "    predictors.subtract_annual_means()\n",
    "    predictors.deseasonalize()\n",
    "\n",
    "    model_input = preprocessing.predictionInput(predictors)\n",
    "    model_input.stack_predictor_coords()\n",
    "    model_input.standardize()\n",
    "    x_in = model_input.get_windowed_filtered_np_input(n_steps)\n",
    "\n",
    "    for model_fn in model_fns:\n",
    "        model = keras.models.load_model(model_fn)\n",
    "        y_out = model.predict(x_in)\n",
    "\n",
    "        #backtransform using era5 obs\n",
    "        y_train_mean = np.nanmean(performance.o.sel(split='train'))\n",
    "        y_train_sd = np.nanstd(performance.o.sel(split='train'),ddof=0)\n",
    "\n",
    "        y_hat = y_out*y_train_sd + y_train_mean\n",
    "        t_hat = predictors.data.time[n_steps-1::]\n",
    "\n",
    "        out_ds = xr.Dataset(data_vars=dict(yhat=([\"time\",\"tg\"], y_hat),y_train_mean = ([\"tg\"],[y_train_mean]),y_train_sd = ([\"tg\"],[y_train_sd])),\n",
    "              coords=dict(time=t_hat,tg=[tg],lon=performance.lon,lat=performance.lat,),\n",
    "              attrs=dict(model=model_fn, predictors=predictor_path,))\n",
    "\n",
    "        out_ds['hyperparameters'] = hyperparams.isel(split=0,drop=True).isel(i=int(model_fn.split('_')[-2].replace('i','')))\n",
    "        out_ds.attrs['model'] = model_fn\n",
    "        out_ds.attrs['forcing'] = predictor_path\n",
    "        out_ds.attrs['performance'] = performance_path\n",
    "        out_ds.attrs['predictor_vars'] = predictor_vars\n",
    "\n",
    "        if os.path.exists(out_path)==False:\n",
    "            os.makedirs(out_path)\n",
    "        out_ds.to_netcdf(os.path.join(out_path,out_fn+'_'+'_'.join(model_fn.split('_')[-2::]).replace('.keras','.nc')),mode='w')\n",
    "\n",
    "        del model, out_ds\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e1cadd-93d3-4515-96bb-2e8b3a7bbc4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/dataset.py:255: UserWarning: The specified Dask chunks separate the stored chunks along dimension \"time\" starting at index 198544. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/dataset.py:255: UserWarning: The specified Dask chunks separate the stored chunks along dimension \"lat_around_tg\" starting at index 13. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/dataset.py:255: UserWarning: The specified Dask chunks separate the stored chunks along dimension \"lon_around_tg\" starting at index 13. This could degrade performance. Instead, consider rechunking after loading.\n",
      "  warnings.warn(\n",
      "2025-07-28 08:25:34.228916: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/nvidia/lib64\n",
      "2025-07-28 08:25:34.228953: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 18s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 19s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 16s 2ms/step\n",
      "9090/9090 [==============================] - 16s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 18s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 18s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n",
      "9090/9090 [==============================] - 17s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "out_ds = load_and_predict(performance,tg,model_fns,predictor_path,predictor_vars,out_path,out_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
