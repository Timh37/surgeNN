{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f6db52-8855-4fee-b7dc-a1820c5fa819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''script to regrid CMIP6 datatsets to target grid and store them'''\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import os\n",
    "import intake\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "from xmip.utils import google_cmip_col\n",
    "from xmip.postprocessing import combine_datasets,_concat_sorted_time, merge_variables\n",
    "from cmip_catalogue_operations import reduce_cat_to_max_num_realizations, drop_vars_from_cat, drop_older_versions\n",
    "from cmip_ds_dict_operations import select_period, pr_flux_to_m, drop_duplicate_timesteps, drop_coords, drop_incomplete\n",
    "import xesmf as xe\n",
    "import gcsfs\n",
    "from get_era5_around_tgs import get_era5_around_tgs\n",
    "fs = gcsfs.GCSFileSystem() #list stores, stripp zarr from filename, load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2208f39c-fffe-4116-8601-671042a9fdc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#configure settings\n",
    "output_path = 'gs://leap-persistent/timh37/HighResMIP/surgeNN_predictors/'\n",
    "overwrite_existing = False #whether or not to process files for which output already exists in the output path\n",
    "\n",
    "query_vars = ['psl','uas','vas'] #variables to process\n",
    "required_vars = ['psl','uas','vas'] #variables that includes models should provide\n",
    "\n",
    "highresmip_model = 'HadGEM3-GC31-HM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5cbaaf-3a0d-4851-a158-c6add1bab89f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.sub_experiment_id.variant_label.version.zstore'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13848/521207408.py:5: DeprecationWarning: cdf_kwargs and zarr_kwargs are deprecated and will be removed in a future version. Please use xarray_open_kwargs instead.\n",
      "  ddict = cat.to_dataset_dict(**kwargs) #open datasets into dictionary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6/6 00:06&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#query simulations & manipulate data catalog:\n",
    "col = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/cmip6-pgf-ingestion-test/catalog/catalog.json\") #temporary pangeo-leap-forge catalogue\n",
    "cat = col.search(activity_id='HighResMIP',table_id=['3hr','E3hr'],source_id=[highresmip_model],experiment_id=['highres-future','hist-1950'],variable_id=['psl','vas','uas'])#table_id='3hr',require_all_on=['member_id','grid_label','experiment_id'])\n",
    "kwargs = {'zarr_kwargs':{'consolidated':True,'use_cftime':True},'aggregate':False} #keyword arguments for generating dictionary of datasets from cmip6 catalogue\n",
    "ddict = cat.to_dataset_dict(**kwargs) #open datasets into dictionary\n",
    "ddict = drop_duplicate_timesteps(ddict) #remove duplicate timesteps from ds if present\n",
    "ddict = drop_coords(ddict,['bnds','nbnd','height']) #remove some unused auxiliary coordinates\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "    hist_fut = combine_datasets(ddict,_concat_sorted_time,match_attrs =['source_id', 'grid_label','table_id','variant_label','variable_id'],combine_func_kwargs={'join':'inner','coords':'minimal'})    \n",
    "hist_fut = drop_duplicate_timesteps(hist_fut) \n",
    "hist_fut = drop_incomplete(hist_fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c82a304-2d73-42f3-acad-e706d115909f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44ddd96293e45ad9b397a0141893d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#regrid to sufficiently large grid to derive predictors around TGs, at ERA5 resolution\n",
    "target_grid = xr.Dataset( #grid to interpolate CMIP6 simulations to\n",
    "        {   \"longitude\": ([\"longitude\"], np.arange(-13,13,.25), {\"units\": \"degrees_east\"}),\n",
    "            \"latitude\": ([\"latitude\"], np.arange(63,34,-.25), {\"units\": \"degrees_north\"}),})\n",
    "\n",
    "regridded_datasets = defaultdict(dict)\n",
    "for key,ds in tqdm(hist_fut.items()):\n",
    "    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "    ds = ds.sortby(ds.lon)\n",
    "\n",
    "    ds = ds.where((ds.lat>30)&(ds.lat<65)&(ds.lon>-15)&(ds.lon<15),drop=True) #not sure if necessary/more efficient\n",
    "    ds = ds.isel(sub_experiment_id=0,drop=True) #remove this coordinate\n",
    "    \n",
    "    regridder = xe.Regridder(ds,target_grid,'bilinear',ignore_degenerate=True,periodic=True)\n",
    "    regridded_ds = regridder(ds.chunk({'time':2000,'lat':10000,'lon':10000}),keep_attrs=True)\n",
    "\n",
    "    regridded_datasets[key] = regridded_ds.unify_chunks().chunk({'time':500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847204a9-4642-4444-a798-b8f7780ec67a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictors_eu = xr.merge(list(regridded_datasets.values()))\n",
    "predictors_eu  = predictors_eu.rename({'vas':'v10','uas':'u10','psl':'msl'})\n",
    "predictors_eu.attrs['resolution'] = '0p25x0p25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca0cfcb-c15a-48e8-b08b-92d87495e7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictors_eu = predictors_eu.load() #this takes a while (~40GB, depending on target grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31b2746-52df-4073-8265-57396adb5ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77dfa78d9aa468a94e55a1bda9f94ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: stavanger-svg-nor-nhs.csv\n",
      "processing: wick-wic-gbr-bodc.csv\n",
      "processing: esbjerg-esb-dnk-dmi.csv\n",
      "processing: immingham-imm-gbr-bodc.csv\n",
      "processing: den_helder-denhdr-nld-rws.csv\n",
      "processing: fishguard-fis-gbr-bodc.csv\n",
      "processing: brest-822a-fra-uhslc.csv\n",
      "processing: vigo-vigo-esp-ieo.csv\n",
      "processing: alicante_i_outer_harbour-alio-esp-da_mm.csv\n"
     ]
    }
   ],
   "source": [
    "#get predictors around each tide gauge and store\n",
    "grid_size_around_tgs=5 #degrees around TGs\n",
    "tg_coords = xr.open_dataset('../gesla3_tg_coordinates_eu.nc')#.sel(tg=['den_helder-denhdr-nld-rws.csv']) #load TG coordinates\n",
    "\n",
    "tgs        = ['stavanger-svg-nor-nhs.csv','wick-wic-gbr-bodc.csv','esbjerg-esb-dnk-dmi.csv',\n",
    "                  'immingham-imm-gbr-bodc.csv','den_helder-denhdr-nld-rws.csv', 'fishguard-fis-gbr-bodc.csv',  \n",
    "                  'brest-822a-fra-uhslc.csv', 'vigo-vigo-esp-ieo.csv',  'alicante_i_outer_harbour-alio-esp-da_mm.csv']\n",
    "\n",
    "for output_tg in tqdm(tgs):#tg_coords.tg.values:\n",
    "    print('processing: '+output_tg)\n",
    "    predictors = get_era5_around_tgs(predictors_eu,grid_size_around_tgs,tg_coords.sel(tg=[output_tg])).chunk({'tg':1,'time':1000000})\n",
    "    predictors = predictors.isel(variant_label=0,tg=0)\n",
    "\n",
    "    output_fn = os.path.join(output_path,'predictors_'+predictors.source_id+'_'+str(predictors.time.dt.year[0].values)+'_'+str(predictors.time.dt.year[-1].values)+'_'+output_tg.replace('.csv','')+'.zarr')\n",
    "    predictors.to_zarr(output_fn,mode='w') #store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7d85b8-625f-47e4-9529-59728943f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "var_names = ['msl','u10','v10','w']\n",
    "\n",
    "if 'w' in var_names and 'w' not in predictors.variables:\n",
    "    predictors['w'] = np.sqrt((predictors.u10**2+predictors.v10**2))\n",
    "    \n",
    "for var in var_names: #remove amean\n",
    "    predictors[var] = predictors[var].groupby(predictors.time.dt.year) - predictors[var].groupby(predictors.time.dt.year).mean('time') #remove annual means\n",
    "    predictors[var] = deseasonalize_da(predictors[var]) #remove mean seasonal cycle\n",
    "\n",
    "predictors = (predictors - predictors.mean(dim='time'))/predictors.std(dim='time',ddof=0) #standardize\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
